x.train <- model.matrix(Class ~., data_train)[,-1] #on retire l'intercept!
proba.lasso.train = lasso.fit %>% predict(newx=x.train)
predicted.classes.lasso.train = ifelse(proba.lasso.train > seuil, "Kecimen", "Besni")
1-mean(predicted.classes.lasso.train == data_train$Class) #0.155
#modele SVM
pred_train = predict(res.svm,data_train)
1-mean(pred_train==data_train$Class) #0.135
#modele complet
predicted.classes.complet.test = ifelse(proba.complet.test >seuil, "Kecimen", "Besni")
acc = mean(predicted.classes.complet.test == data_test$Class) #0.8616667
1- acc #0.134594
#modele 2 premiere composantes principales
proba.princ.test = res.glm.prin %>% predict(data_test, type = "response")
predicted.classes.princ.test = ifelse(proba.princ.test >seuil, "Kecimen", "Besni")
acc = mean(predicted.classes.princ.test == data_test$Class) #0.8616667
1- acc #0.1290323
#modele AIC
proba.aic.test = glm.AIC %>% predict(data_test, type = "response")
predicted.classes.aic.test = ifelse(proba.aic.test >seuil, "Kecimen", "Besni")
1-mean(predicted.classes.aic.test == data_test$Class) #0.137931
#modele lasso
x.test <- model.matrix(Class ~., data_test)[,-1] #on retire l'intercept!
proba.lasso.test = lasso.fit %>% predict(newx=x.test)
predicted.classes.lasso.test = ifelse(proba.lasso.test > seuil, "Kecimen", "Besni")
1-mean(predicted.classes.lasso.test == data_test$Class) #0.1535039
#modele SVM
pred_test = predict(res.svm,data_test)
1-mean(pred_test==data_test$Class) #0.1290323
comp1 = res$ind$coord[train,1]
comp2 = res$ind$coord[train,2]
data3 = as.data.frame(cbind(Class=data_train$Class,dim1 = comp1,dim2 = comp2))
plot(data3)
data3 = as.data.frame(cbind(Class=as.factor(data_train$Class),dim1 = comp1,dim2 = comp2))
plot(data3)
comp1 = res$ind$coord[train,1]
comp2 = res$ind$coord[train,2]
comp1 = res$ind$coord[train,1]
res$ind$coord[train,1]
res.pca3=PCA(data_train, ncp = 2, quali.sup = p, graph = FALSE)
View(data.scale)
#set.seed(1)
#n = nrow(data)
#train = sample(c(TRUE,FALSE),n,rep=TRUE,prob=c(2/3,1/3))
#data_train = cbind(Class = data$Class,as.data.frame(res$ind$coord))[train,]
data_train2 = cbind(Class = data$Class,as.data.frame(data.scale))[train,]
#data_test = cbind(Class = data$Class,as.data.frame(res$ind$coord))[!train,]
data_test2 = cbind(Class = data$Class,as.data.frame(data.scale))[!train,]
res.pca3=PCA(data_train2, ncp = 2, quali.sup = p, graph = FALSE)
#set.seed(1)
#n = nrow(data)
#train = sample(c(TRUE,FALSE),n,rep=TRUE,prob=c(2/3,1/3))
#data_train = cbind(Class = data$Class,as.data.frame(res$ind$coord))[train,] #data train is after pca
data_train2 = cbind(as.data.frame(data.scale),Class = data$Class)[train,] # need own data.train to apply pca to
#data_test = cbind(Class = data$Class,as.data.frame(res$ind$coord))[!train,]
data_test2 = cbind(as.data.frame(data.scale,Class = data$Class))[!train,]
res.pca3=PCA(data_train2, ncp = 2, quali.sup = p, graph = FALSE)
#data_test = cbind(Class = data$Class,as.data.frame(res$ind$coord))[!train,]
data_test2 = cbind(as.data.frame(data.scale),Class = data$Class)[!train,]
summary(res.pca3)
res.pca3=PCA(data_train2, ncp = 2, quali.sup = p, graph = TRUE)
supcol(res.pca3,data_test2)
install.packages("ade4")
library(ade4)
supcol(res.pca3,data_test2)
suprow(res.pca3,data_test2)
suprow(res.pca3,data_test2)
resproj.pca3 <- suprow(res.pca3, data_test2)
#########Projet final de STAT203#############################
#setwd("~/ENSTA 2A/STA203")
setwd("~/Documents/STA203/STA203")
library("openxlsx")
rm(list=objects()) ; graphics.off()
data = read.xlsx("Raisin.xlsx",colNames=TRUE)
#################################################################### PARTIE 1
#-------------------------------------------question 1
#Analyse uni-variee : boxplot
p = ncol(data)
boxplot(data[,c(1,5)])
boxplot(data[,-p])
boxplot(data[,c(2,3)]) #axis length
boxplot(data[,c(4,6)])#excentricite extent
boxplot(data[,c(7)]) #perimetre
#Analyse bi-vari?e
#matrice de correlation
round(cor(data[-p]),2)
library(corrplot)
corrplot(cor(data[,-p]), method="circle")
pairs(data[,-p],col=ifelse(data$Class=="Kecimen", "black", "red"))
# pour regarder de plus pr?t les r?partitions
ggplot(data,aes(x=data$Area,y=data$Perimeter,color=as.factor(data$Class))) + geom_point()
#---------------------------------question 2 : ACP
library("FactoMineR")
data$Class = as.factor(data$Class)
res.PCA=PCA(data,quali.sup = p, graph = TRUE)
plt1=plot(res.PCA,axes=c(1,2),choix="ind",label="quali", habillage=p) +
theme(legend.position = "none")
plt2=plot(res.PCA,axes=c(2,3),choix="ind",label="quali", habillage=p)
plt4=plot(res.PCA,axes=c(6,5),choix="ind",label="quali", habillage=p)
plt4
plt3 = plot(res.PCA,choix="var")
cowplot::plot_grid(plt1, plt3, nrow=1, ncol=2)
barplot(res.PCA$eig[,1])
res.PCA$var$cos2[,1:2]
# > res$var$cos2[,1:2]
#                  Dim.1       Dim.2
# Area            0.97109063 0.019587803
# MajorAxisLength 0.94935877 0.027110793
# MinorAxisLength 0.73266049 0.204270120
# Eccentricity    0.19907684 0.542191863
# ConvexArea      0.98262357 0.011155576
# Extent          0.01535408 0.647175333
# Perimeter       0.98212422 0.001696952
#----------------------------------Question 3.1 - k-means
# K-means
n = nrow(data)
set.seed(1)
centres = data[sample(1:n,2),-p]
centres = data[1:2,-p]
res.kmeans = kmeans (data[-p],centres)
#erreur de classification
table(pred=res.kmeans$cluster,vrai=data$Class)
#normalisation des variables
data.scale= scale(data[-p])
centres.scale = data.scale[sample(1:n,2),-p]
centres.scale = data.scale[1:2,-p]
res.kmeans.scale = kmeans(data.scale,centres.scale)
#erreur de classification avec var normalisees
table(pred=res.kmeans.scale$cluster,vrai=data$Class)
#----------------------------------question3.2- Classification hierarchique
d.data = dist(data[,-p])
cah.ward = hclust(d.data, method="ward.D2")
cah.ward
#Cluster method   : ward.D2
#Distance         : euclidean
#Number of objects: 900
plot(cah.ward, cex=0.5)
#avec variables normalis√©es
d.data2 = dist(data.scale)
cah.ward2 = hclust(d.data2, method="ward.D2")
cah.ward2
plot(cah.ward2, cex=0.5)
# dendrogram with highlighting of the groups
rect.hclust(cah.ward2,k=2)
# partition in 4 groups
groupes.cah <- cutree(cah.ward2,k=2)
# assignment of the instances to clusters
print(sort(groupes.cah))
plot(as.factor(groupes.cah))
#erreur de classification
table(pred=as.factor(groupes.cah),vrai=data$Class)
#-------------------------------------------------Question 4
#for (i in 1:7) {
#  res.pca2 = PCA(data.scale, ncp = i, graph=FALSE)
#  res.hcpc <- HCPC(res.pca2, graph = FALSE)
#}
res.pca2 = PCA(data.scale, ncp = 1, graph=FALSE)
summary(res.pca2)
res.hcpc = HCPC(res.pca2, nb.clust=2, graph = TRUE)
groupes.hcpc1 = res.hcpc$data.clust$clust
table(pred=groupes.hcpc1,vrai=data$Class) #erreur de classification = 214
res.pca2 = PCA(data.scale, ncp = 2, graph=FALSE)
res.hcpc = HCPC(res.pca2, nb.clust=2, graph = TRUE)
groupes.hcpc2 = res.hcpc$data.clust$clust
table(pred=groupes.hcpc2,vrai=data$Class) #erreur de classification = 214
table(un=groupes.hcpc1,deux=groupes.hcpc2)
res.pca2 = PCA(data.scale, ncp = 3, graph=FALSE)
res.hcpc = HCPC(res.pca2, nb.clust=2, graph = TRUE)
groupes.hcpc3 = res.hcpc$data.clust$clust
table(pred=groupes.hcpc3,vrai=data$Class) #erreur de classification = 209
res.pca2 = PCA(data.scale, ncp = 4, graph=FALSE)
res.hcpc = HCPC(res.pca2, nb.clust=2, graph = TRUE)
groupes.hcpc4 = res.hcpc$data.clust$clust
table(pred=groupes.hcpc4,vrai=data$Class) #erreur de classification = 209
res.pca2 = PCA(data.scale, ncp = 5, graph=FALSE)
res.hcpc = HCPC(res.pca2, nb.clust=2, graph = TRUE)
groupes.hcpc5 = res.hcpc$data.clust$clust
table(pred=groupes.hcpc5,vrai=data$Class) #erreur de classification = 209
res.pca2 = PCA(data.scale, ncp = 6, graph=FALSE)
res.hcpc = HCPC(res.pca2, nb.clust=2, graph = TRUE)
groupes.hcpc6 = res.hcpc$data.clust$clust
table(pred=groupes.hcpc6,vrai=data$Class) #erreur de classification = 209
res.pca2 = PCA(data.scale, ncp = 7, graph=FALSE)
res.hcpc = HCPC(res.pca2, nb.clust=2, graph = TRUE)
groupes.hcpc7 = res.hcpc$data.clust$clust
table(pred=groupes.hcpc7,vrai=data$Class) #erreur de classification = 209
#for pretty graphs
#library("factoextra")
#fviz_dend(res.hcpc,
#          cex = 0.7,                     # Taille du text
#          palette = "jco",               # Palette de couleur ?ggpubr::ggpar
#          rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
#          rect_border = "jco",           # Couleur du rectangle
#          labels_track_height = 0.8      # Augment l'espace pour le texte
#)
#fviz_cluster(res.hcpc,
#             repel = TRUE,            # Evite le chevauchement des textes
#             show.clust.cent = TRUE, # Montre le centre des clusters
#             palette = "jco",         # Palette de couleurs, voir ?ggpubr::ggpar
#             ggtheme = theme_minimal(),
#             main = "Factor map"
#)
########################################################### PARTIE 2
#-------------------------------------------------question2
set.seed(1)
n = nrow(data)
train = sample(c(TRUE,FALSE),n,rep=TRUE,prob=c(2/3,1/3))
res=res.PCA
data_train = cbind(Class = data$Class,as.data.frame(res$ind$coord))[train,]
data_test = cbind(Class = data$Class,as.data.frame(res$ind$coord))[!train,]
#modele complet
res.glm.complet = glm(Class~.,
family=binomial,data=data_train)
summary(res.glm.complet)
#modele deux composantes principales
comp1 = res$ind$coord[train,1]
comp2 = res$ind$coord[train,2]
new = as.data.frame(cbind(Class=data_train$Class,dim1 = comp1,dim2 = comp2))
res.glm.prin = glm(Class~(Dim.1+Dim.2) ,family=binomial,data=data_train )
summary(res.glm.prin)
library(magrittr)
probabilities = res.glm.prin %>% predict(data_test, type = "response")
predicted.classes = ifelse(probabilities > 0.5, "Kecimen", "Besni")
mean(predicted.classes == data_test$Class) #0.8709677
library(tidyverse)
library(caret)
data_train %>%
mutate(prob = ifelse(Class == "Kecimen", 1, 0)) %>%
ggplot(aes(Dim.1+Dim.2, prob)) +
geom_point(alpha = 0.2) +
geom_smooth(method = "glm", method.args = list(family = "binomial")) +
labs(
title = "Logistic Regression Model",
x = "Dim1 + Dim2",
y = "Probability of being Kecimen"
)
# modele par AIC
glm = glm(Class~.,family=binomial,data=data_train)
selection=MASS::stepAIC(glm,direction="both")
glm.AIC = glm(Class~Dim.1+Dim.2 + Dim.3 + Dim.5,family=binomial,data=data_train)
probabilities = glm.AIC %>% predict(data_test, type = "response")
predicted.classes = ifelse(probabilities > 0.5, "Kecimen", "Besni")
mean(predicted.classes == data_test$Class) #0.862069
# modele obtenu par regression penalisee lasso
library(glmnet)
x = as.matrix(data_train[,-1])
y = data_train$Class
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
lasso.fit = glmnet(x,y,family = "binomial",alpha=1,,lambda=cv.lasso$lambda.min)
x.test <- model.matrix(Class ~., data_test)[,-1] #on retire l'intercept!
probabilities = lasso.fit %>% predict(newx=x.test)
predicted.classes = ifelse(probabilities > 0.5, "Kecimen", "Besni")
predicted.classes
mean(predicted.classes == data_test$Class) #0.8464961
#-----------------------------------------------------question 3 : SVM
#SVM lineaire
library(e1071)
co= cbind(0.001, 0.01, 0.1, 1, 5, 10, 100)
obj = tune.svm(Class~Dim.1+Dim.2, data=data_train , kernel ='linear', scale =FALSE,tunecontrol=tune.control(cross=2), cost = co) #trouver meilleur cout
res.svm = svm(Class~Dim.1+Dim.2, data=data_train , kernel ='linear', scale =FALSE,cost= 1)
summary(res.svm)
plot(res.svm, data_train,Dim.2~Dim.1 )
# pred      Besni Kecimen
# Besni     250      37
# Kecimen    43     270
#SVM noyau polynomial
obj = tune.svm(Class~Dim.1+Dim.2, data=data_train , kernel ='linear', scale =FALSE,tunecontrol=tune.control(cross=2), cost = co ,coef0 = (0:10), degree = (1:10))
res.svm = svm(Class~Dim.1+Dim.2, data=data_train , kernel ='polynomial',scale = FALSE,cost= 1,coef0=0, degree=1)
summary(res.svm)
plot(res.svm, data_train,Dim.2~Dim.1 )
table(pred=predict(res.svm),vrai=data_train$Class)
# vrai
# pred      Besni Kecimen
# Besni     250      38
# Kecimen    43     269
test_pred = predict(res.svm, newdata = data_test)
table(pred = test_pred,vrai = data_test$Class)
#--------------------------------------question 4 : courbe ROC
#courbe roc pour modele complet test et appentissage superpose
library(ROCR)
proba.complet.test = res.glm.complet %>% predict(data_test, type = "response")
pred = prediction(proba.complet.test,data_test$Class)
ROC = performance(pred,"sens","fpr")
plot(ROC, xlab="1-specif", main="courbes ROC")
lines(c(0,1),c(0,1),lty=2)
proba.complet.train = res.glm.complet %>% predict(data_train, type = "response")
pred.train = prediction(proba.complet.train,data_train$Class)
ROC_train = performance(pred.train,"sens","fpr")
plot(ROC_train, xlab="1-specif", main="courbes ROC",col =2,add=TRUE)
legend("bottomright",legend= c(paste("echantillon d'apprentissage"),
paste("echantillon de test")
), col=1:2, lty=1)
#Courbe des 4 modele de la question 2 sur echantillon test
proba.complet.test = res.glm.complet %>% predict(data_test, type = "response")
pred_complet = prediction(proba.complet.test,data_test$Class)
class(pred_complet)
mode(pred_complet)
ROC_complet = performance(pred,"sens","fpr")
plot(ROC_complet, xlab="1-specif", main="courbes ROC",legend = "complet")
proba.princ.test = res.glm.prin %>% predict(data_test, type = "response")
pred_princ = prediction(proba.princ.test,data_test$Class)
class(pred_princ)
mode(pred_princ)
ROC_princ = performance(pred,"sens","fpr")
plot(ROC_princ, xlab="1-specif", main="courbes ROC",col=2,add=TRUE,legend="2 CP")
x.test <- model.matrix(Class ~., data_test)[,-1] #on retire l'intercept!
proba.lasso.test = lasso.fit %>% predict(newx=x.test)
pred_lasso = prediction(proba.lasso.test,data_test$Class)
class(pred_lasso)
mode(pred_lasso)
ROC_lasso = performance(pred_lasso,"sens","fpr")
plot(ROC_lasso, xlab="1-specif", main="courbes ROC",col=3,add=TRUE,legend="Lasso")
proba.aic.test = glm.AIC %>% predict(data_test, type = "response")
pred_AIC = prediction(proba.aic.test,data_test$Class)
class(pred_AIC)
mode(pred_AIC)
ROC_AIC = performance(pred_AIC,"sens","fpr")
plot(ROC_AIC, xlab="1-specif", main="courbes ROC",col=4,add=TRUE,legend="AIC")
perf1= performance(pred_complet, "auc")
(AUC1=round(unlist(perf1@y.values),4) )
perf2 = performance(pred_princ, "auc")
(AUC2=round(unlist(perf2@y.values),4) )
perf3 = performance(pred_lasso, "auc")
(AUC3=round(unlist(perf3@y.values),4) )
perf4 = performance(pred_AIC, "auc")
(AUC4=round(unlist(perf4@y.values),4) )
legend("bottomright",legend= c(paste("AUC complet: ",AUC1),
paste("AUC 2 CP: ",AUC2),
paste("AUC lasso: ",AUC3),
paste("AUC AIC: ",AUC4)
), col=1:4, lty=1)
#--------------------------------------------------QUESTION 5
#on cherche le meilleur seuil
pred_AIC %>%
performance(measure = "tpr", x.measure = "fpr") -> result
plotdata <- data.frame(x = result@x.values[[1]],
y = result@y.values[[1]],
p = result@alpha.values[[1]])
dist_vec <- plotdata$x^2 + (1 - plotdata$y)^2
opt_pos <- which.min(dist_vec)
seuil = plotdata[opt_pos, ]$p  #0.0505
###############en apprentissage##########################
#modele complet
predicted.classes.complet.app = ifelse(proba.complet.train >seuil, "Kecimen", "Besni")
acc = mean(predicted.classes.complet.app == data_train$Class) #0.8616667
1- acc #0.1383333
#modele 2 premiere composantes principales
proba.princ.train = res.glm.prin %>% predict(data_train, type = "response")
predicted.classes.princ.train = ifelse(proba.princ.train >seuil, "Kecimen", "Besni")
acc = mean(predicted.classes.princ.train == data_train$Class) #0.8616667
1- acc #0.1333333
#modele AIC
proba.aic.train = glm.AIC %>% predict(data_train, type = "response")
predicted.classes.aic.app = ifelse(proba.aic.train >seuil, "Kecimen", "Besni")
1-mean(predicted.classes.aic.app == data_train$Class) #0.8583333 0.1416667
#modele lasso
x.train <- model.matrix(Class ~., data_train)[,-1] #on retire l'intercept!
proba.lasso.train = lasso.fit %>% predict(newx=x.train)
predicted.classes.lasso.train = ifelse(proba.lasso.train > seuil, "Kecimen", "Besni")
1-mean(predicted.classes.lasso.train == data_train$Class) #0.155
#modele SVM
pred_train = predict(res.svm,data_train)
1-mean(pred_train==data_train$Class) #0.135
######en test###############################
#modele complet
predicted.classes.complet.test = ifelse(proba.complet.test >seuil, "Kecimen", "Besni")
acc = mean(predicted.classes.complet.test == data_test$Class) #0.8616667
1- acc #0.134594
#modele 2 premiere composantes principales
proba.princ.test = res.glm.prin %>% predict(data_test, type = "response")
predicted.classes.princ.test = ifelse(proba.princ.test >seuil, "Kecimen", "Besni")
acc = mean(predicted.classes.princ.test == data_test$Class) #0.8616667
1- acc #0.1290323
#modele AIC
proba.aic.test = glm.AIC %>% predict(data_test, type = "response")
predicted.classes.aic.test = ifelse(proba.aic.test >seuil, "Kecimen", "Besni")
1-mean(predicted.classes.aic.test == data_test$Class) #0.137931
#modele lasso
x.test <- model.matrix(Class ~., data_test)[,-1] #on retire l'intercept!
proba.lasso.test = lasso.fit %>% predict(newx=x.test)
predicted.classes.lasso.test = ifelse(proba.lasso.test > seuil, "Kecimen", "Besni")
1-mean(predicted.classes.lasso.test == data_test$Class) #0.1535039
#modele SVM
pred_test = predict(res.svm,data_test)
1-mean(pred_test==data_test$Class) #0.1290323
#################################################################### PARTIE III
#-----------------------------------------------------------question 1
#set.seed(1)
#n = nrow(data)
#train = sample(c(TRUE,FALSE),n,rep=TRUE,prob=c(2/3,1/3))
data_train2 = cbind(as.data.frame(data.scale),Class = data$Class)[train,] # need own data.train to apply pca to
data_test2 = cbind(as.data.frame(data.scale),Class = data$Class)[!train,]
#set.seed(1)
#n = nrow(data)
#train = sample(c(TRUE,FALSE),n,rep=TRUE,prob=c(2/3,1/3))
#data_train2 = cbind(as.data.frame(data.scale),Class = data$Class)[train,] # need own data.train to apply pca to
#data_test2 = cbind(as.data.frame(data.scale),Class = data$Class)[!train,]
data_train2 = as.data.frame(data.scale)[train,] # need own data.train to apply pca to
data_test2 = as.data.frame(data.scale)[!train,]
#set.seed(1)
#n = nrow(data)
#train = sample(c(TRUE,FALSE),n,rep=TRUE,prob=c(2/3,1/3))
#data_train2 = cbind(as.data.frame(data.scale),Class = data$Class)[train,] # need own data.train to apply pca to
#data_test2 = cbind(as.data.frame(data.scale),Class = data$Class)[!train,]
data_train2 = as.data.frame(data.scale)[train,] # need own data.train to apply pca to
data_test2 = as.data.frame(data.scale)[!train,]
#res.pca3=PCA(data_train2, ncp = 2, quali.sup = p, graph = TRUE)
res.pca3=dudi.pca(data_train2, scannf = TRUE, nf = 2)
#res.pca3=PCA(data_train2, ncp = 2, quali.sup = p, graph = TRUE)
library(ade4)
res.pca3=dudi.pca(data_train2, scannf = TRUE, nf = 2)
summary(res.pca3)
resplusproj.pca3 <- suprow(res.pca3, data_test2)
res.pca3$eig==resplusproj.pca3$eig
res.pca3 <- suprow(res.pca3, data_test2) #projection
#res.pca3=PCA(data_train2, ncp = 2, quali.sup = p, graph = TRUE)
res.pca3=dudi.pca(data_train2, scannf = FALSE, nf = 2)
summary(res.pca3)
res.pca3=cbind(res.pca3,suprow(res.pca3, data_test2)) #projection
rm(res.pca3)
#res.pca3=PCA(data_train2, ncp = 2, quali.sup = p, graph = TRUE)
rm(res.pca3)
res.pca3=dudi.pca(data_train2, scannf = FALSE, nf = 2)
summary(res.pca3)
res.pca3=cbind(res.pca3,suprow(res.pca3, data_test2)) #projection
#res.pca3=PCA(data_train2, ncp = 2, quali.sup = p, graph = TRUE)
rm(res.pca3)
res.pca3=dudi.pca(data_train2, scannf = FALSE, nf = 2)
summary(res.pca3)
res.pca3=cbind(res.pca3,suprow(res.pca3, data_test2)) #projection
#res.pca3=PCA(data_train2, ncp = 2, quali.sup = p, graph = TRUE)
rm(res.pca3)
res.pca3=dudi.pca(data_train2, scannf = FALSE, nf = 2)
summary(res.pca3)
#res.pca3=cbind(res.pca3,suprow(res.pca3, data_test2)) #projection
proj=suprow(res.pca3, data_test2)
rm(resplusproj.pca3)
rm(proj)
View(data_test2)
#res.pca3=cbind(res.pca3,suprow(res.pca3, data_test2)) #projection
res.pca3plusproj=suprow(res.pca3, data_test2)
res.pca3full=rbind(res.pca3,res.pca3plusproj)
res.pca3full=cbind(res.pca3,res.pca3plusproj)
rm(res.pca3)
res.pca3=dudi.pca(data_train2, scannf = FALSE, nf = 2)
summary(res.pca3)
#res.pca3=cbind(res.pca3,suprow(res.pca3, data_test2)) #projection
res.pca3plusproj=suprow(res.pca3, data_test2)
res.pca3[nrow(res.pca3) + 1,] <- res.pca3plusproj$tabsup
res.pca3[nrow(res.pca3) + 1,] <- res.pca3plusproj$lisup
#res.pca3=PCA(data_train2, ncp = 2, quali.sup = p, graph = TRUE)
rm(res.pca3full)
library(ade4)
data_train2 = as.data.frame(data.scale)[train,] # need own data.train to apply pca to
data_test2 = as.data.frame(data.scale)[!train,]
#res.pca3=PCA(data_train2, ncp = 2, quali.sup = p, graph = TRUE)
rm(res.pca3)
res.pca3=dudi.pca(data_train2, scannf = FALSE, nf = 2)
summary(res.pca3)
res.pca3plusproj=suprow(res.pca3, data_test2)
res.pca3
plot(res.pca3)
plot(res.pca3)
plot(res.pca3.li)
plot(res.pca3$li)
plot(res.pca3plusproj$lisup)
plot(res.pca3$li)
plot(res.pca3$li)
plot(res.pca3plusproj$lisup)
plot(res.pca3$li)
plot(res.pca3plusproj$lisup)
plot(res.pca3$li)
plot(res.pca3plusproj$lisup)
plot(res.pca3$li)
uhmmm=as.data.frame(cbind(res.pca3$li,res.pca3plusproj$lisup))
uhmmm=(cbind(res.pca3$li,res.pca3plusproj$lisup))
uhmmm=cbind(res.pca3$li,res.pca3plusproj$lisup)
uhmmm=rbind(res.pca3$li,res.pca3plusproj$lisup)
full=rbind(res.pca3$li,res.pca3plusproj$lisup)
plot(full)
plot(full)
#plot(res.pca3$li)
#plot(res.pca3plusproj$lisup)
plot(full,col=as.factor(cbind(rep("train", 600),rep("projected tests",300))))
plot(res.pca3$li)
#plot(res.pca3$li)
#plot(res.pca3plusproj$lisup)
plot(full,col=as.factor(cbind(rep("train", 600),rep("projected tests",300))))
legend(1, 95, legend=c("train", "projected tests"),
col=c("red", "proj"), lty=1:2, cex=0.8)
legend(1, 95, legend=c("train", "projected tests"),
col=c("red", "black"), lty=1:2, cex=0.8)
legend(legend=c("train", "projected tests"),
col=c("red", "black"), lty=1:2, cex=0.8)
legend(x=100, legend=c("train", "projected tests"),
col=c("red", "black"), lty=1:2, cex=0.8)
#plot(res.pca3$li)
#plot(res.pca3plusproj$lisup)
plot(full,col=as.factor(cbind(rep("train", 600),rep("projected tests",300))))
legend(x=100, legend=c("train", "projected tests"),
col=c("red", "black"))
legend(1,95, legend=c("train", "projected tests"),
col=c("red", "black"))
plot(perf, xlab="1-specif", main="courbes ROC",col=5,add=TRUE,legend="AIC")
legend("bottomright",legend= c(paste("AUC complet: ",AUC1),
paste("AUC 2 CP: ",AUC2),
paste("AUC lasso: ",AUC3),
paste("AUC AIC: ",AUC4),
paste("AUC LDA :", AUC5)
), col=1:5, lty=1)
#plot(res.pca3$li)
#plot(res.pca3plusproj$lisup)
plot(full,col=as.factor(cbind(rep("train", 600),rep("projected tests",300))),legend="aic")
